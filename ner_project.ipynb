{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS182 Final Project\n",
    "\n",
    "### Named-Entity Recognition using an HMM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that building the tagger will have a large enough scope, especially when you show different approaches/ideas and try to maximize your scores. I am also happy to discuss in person early next week. \n",
    "\n",
    "Regarding your ideas: I am not sure why you want a full Bayes-Net - I believe a HMM+Viterbi is sufficient for the task so I recommend implementing that. Here are slides from CS287 that talk about NER and how to approach the problem: https://cs287.github.io/Lectures/slides/lecture14-search.pdf\n",
    "It could be useful for you to compare the performance between the forward and viterbi algorithm here. \n",
    "\n",
    "When you consider more information, please be wary that HMMs/Bayes-Nets have the Markov assumption. You need to be careful when taking previous and following words into account that you don’t violate that assumption. Depending on the size of your corpus, cross-validation might also not be necessary and a simple train/valid/test split could be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 281837: expected 25 fields, saw 34\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemma</th>\n",
       "      <th>next-lemma</th>\n",
       "      <th>next-next-lemma</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-shape</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-shape</th>\n",
       "      <th>next-word</th>\n",
       "      <th>...</th>\n",
       "      <th>prev-prev-lemma</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-shape</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-shape</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>shape</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thousand</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>...</td>\n",
       "      <td>__start2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>...</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>...</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>...</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>london</td>\n",
       "      <td>NNP</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>...</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     lemma next-lemma next-next-lemma next-next-pos  \\\n",
       "0           0  thousand         of        demonstr           NNS   \n",
       "1           1        of   demonstr            have           VBP   \n",
       "2           2  demonstr       have           march           VBN   \n",
       "3           3      have      march         through            IN   \n",
       "4           4     march    through          london           NNP   \n",
       "\n",
       "  next-next-shape next-next-word next-pos next-shape      next-word ...  \\\n",
       "0       lowercase  demonstrators       IN  lowercase             of ...   \n",
       "1       lowercase           have      NNS  lowercase  demonstrators ...   \n",
       "2       lowercase        marched      VBP  lowercase           have ...   \n",
       "3       lowercase        through      VBN  lowercase        marched ...   \n",
       "4     capitalized         London       IN  lowercase        through ...   \n",
       "\n",
       "  prev-prev-lemma prev-prev-pos prev-prev-shape prev-prev-word   prev-shape  \\\n",
       "0      __start2__    __START2__        wildcard     __START2__     wildcard   \n",
       "1      __start1__    __START1__        wildcard     __START1__  capitalized   \n",
       "2        thousand           NNS     capitalized      Thousands    lowercase   \n",
       "3              of            IN       lowercase             of    lowercase   \n",
       "4        demonstr           NNS       lowercase  demonstrators    lowercase   \n",
       "\n",
       "       prev-word sentence_idx        shape           word tag  \n",
       "0     __START1__          1.0  capitalized      Thousands   O  \n",
       "1      Thousands          1.0    lowercase             of   O  \n",
       "2             of          1.0    lowercase  demonstrators   O  \n",
       "3  demonstrators          1.0    lowercase           have   O  \n",
       "4           have          1.0    lowercase        marched   O  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"entity-annotated-corpus/ner.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop null rows and check if any null values remaining\n",
    "data.dropna(inplace=True)\n",
    "data[data.isnull().any(axis=1)].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible predictive data: [u'pos', u'shape', u'tag', u'prev-lemma', u'prev-prev-lemma', u'next-word', u'next-lemma', 'Unnamed: 0', u'next-next-word', u'lemma', u'prev-prev-iob', u'sentence_idx', u'next-next-pos', u'prev-iob', u'next-shape', u'prev-shape', u'prev-prev-word', u'next-next-shape', u'next-pos', u'prev-prev-pos', u'word', u'prev-pos', u'prev-prev-shape', u'prev-word', u'next-next-lemma']\n",
      "\n",
      "What do all of these mean?\n",
      "\n",
      "Tags: [u'I-art', u'B-gpe', u'B-art', u'I-per', u'I-tim', u'B-org', u'O', u'B-geo', u'B-tim', u'I-geo', u'B-per', u'I-eve', u'B-eve', u'I-gpe', u'I-org', u'I-nat', u'B-nat']\n",
      "\n",
      "What do all of these mean?\n",
      "\n",
      "Length of data set: 1050794\n"
     ]
    }
   ],
   "source": [
    "# SOME EDA\n",
    "print(\"Possible predictive data: \" + str(list(set(data.columns.values))))\n",
    "print\n",
    "print(\"What do all of these mean?\")\n",
    "print\n",
    "print(\"Tags: \" + str(list(set(data.tag))))\n",
    "print\n",
    "print(\"What do all of these mean?\")\n",
    "print\n",
    "print(\"Length of data set: \" + str(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 24)\n",
      "(80000,)\n"
     ]
    }
   ],
   "source": [
    "data_small = data[:100000]\n",
    "data_valid = data[100001:150000]\n",
    "preds = list(data.columns.values)\n",
    "preds.remove('tag')\n",
    "y_small = data_small['tag']\n",
    "x_small = data_small[preds]\n",
    "\n",
    "# Split into train and test data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_small, y_small, test_size=0.2, random_state=0)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'PRP$', u'VBG', u'VBD', u'``', u'VBN', u'POS', u'VBP', u'WDT', u'JJ', u'WP', u'VBZ', u'DT', u'RP', u'$', u'NN', u',', u'.', u'TO', u'PRP', u'RB', u';', u':', u'NNS', u'NNP', u'VB', u'WRB', u'RRB', u'CC', u'PDT', u'RBS', u'RBR', u'CD', u'LRB', u'EX', u'IN', u'WP$', u'MD', u'NNPS', u'JJS', u'JJR', u'UH']\n",
      "\n",
      "[u'mixedcase', u'lowercase', u'camelcase', u'ending-dot', u'capitalized', u'number', u'abbreviation', u'punct', u'other', u'uppercase', u'contains-hyphen']\n",
      "\n",
      "[u'I-art', u'B-gpe', u'B-art', u'I-per', u'I-tim', u'B-org', u'O', u'B-geo', u'B-tim', u'I-geo', u'B-per', u'I-eve', u'B-eve', u'I-gpe', u'I-org', u'I-nat', u'B-nat']\n"
     ]
    }
   ],
   "source": [
    "pos_list = list(set(x_train['pos']))\n",
    "print(pos_list)\n",
    "print\n",
    "shape_list = list(set(x_train['shape']))\n",
    "print(shape_list)\n",
    "print\n",
    "tag_list = list(set(y_train.values))\n",
    "print(tag_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'I-art', u'B-gpe', u'B-art', u'I-per', u'I-tim', u'B-org', u'O', u'B-geo', u'B-tim', u'I-geo', u'B-per', u'I-eve', u'B-eve', u'I-gpe', u'I-org', u'I-nat', u'B-nat']\n",
      "\n",
      "{u'mixedcase': u'O', u'lowercase': u'O', u'camelcase': u'I-per', u'ending-dot': u'B-per', u'number': u'O', u'capitalized': u'O', u'abbreviation': u'B-geo', u'punct': u'O', u'other': u'O', u'uppercase': u'O', u'contains-hyphen': u'O'}\n",
      "\n",
      "{u'PRP$': u'O', u'VBG': u'O', u'VBD': u'O', u'VBN': u'O', u',': u'O', u'VBP': u'O', u'WDT': u'O', u'JJ': u'O', u'WP': u'O', u'VBZ': u'O', u'DT': u'O', u'RP': u'O', u'$': u'O', u'NN': u'O', u'POS': u'O', u'.': u'O', u'TO': u'O', u'PRP': u'O', u'RB': u'O', u';': u'O', u':': u'O', u'NNS': u'O', u'NNP': u'B-geo', u'``': u'O', u'WRB': u'O', u'RRB': u'O', u'CC': u'O', u'PDT': u'O', u'RBS': u'O', u'RBR': u'O', u'CD': u'O', u'NNPS': u'I-geo', u'EX': u'O', u'IN': u'O', u'WP$': u'O', u'MD': u'O', u'LRB': u'O', u'JJS': u'O', u'JJR': u'O', u'VB': u'O', u'UH': u'O'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build a dict linking shape to likelihood of each tag\n",
    "\n",
    "shape_probs = {}\n",
    "pos_probs = {}\n",
    "\n",
    "# if X shape, then what is the most likely tag?\n",
    "\n",
    "print(tag_list)\n",
    "print\n",
    "\n",
    "for shape in shape_list:\n",
    "    tag_prob_list = []\n",
    "    for tag in tag_list:\n",
    "        count = 0\n",
    "        for i in data_small[data_small['shape'] == shape]['tag']:\n",
    "            if i == tag:\n",
    "                count += 1\n",
    "        tag_prob_list.append(1.0*count/(len(data_small[data_small['shape'] == shape]) + 1.0))\n",
    "    index = tag_prob_list.index(max(tag_prob_list))\n",
    "        \n",
    "    shape_probs[shape] = tag_list[index]\n",
    "    \n",
    "for pos in pos_list:\n",
    "    tag_prob_list = []\n",
    "    for tag in tag_list:\n",
    "        count = 0\n",
    "        for i in data_small[data_small['pos'] == pos]['tag']:\n",
    "            if i == tag:\n",
    "                count += 1\n",
    "        tag_prob_list.append(1.0*count/(len(data_small[data_small['shape'] == pos])  + 1.0))\n",
    "    index = tag_prob_list.index(max(tag_prob_list))\n",
    "        \n",
    "    pos_probs[pos] = tag_list[index]\n",
    "\n",
    "print(shape_probs)\n",
    "print\n",
    "print(pos_probs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of data without a tag (Baseline accuracy if we only predict 'O': 0.846952875635\n",
      "Train Accuracy: 0.853\n",
      "Validation Accuracy: 0.854017080342\n"
     ]
    }
   ],
   "source": [
    "pred_train = []\n",
    "pred_valid = []\n",
    "\n",
    "# make predictions based off of \"shape\"\n",
    "\n",
    "num_O = len(data[data['tag'] == 'O'])\n",
    "percent = 1.0*num_O/len(data)\n",
    "print \"Percent of data without a tag (Baseline accuracy if we only predict 'O': \" + str(percent)\n",
    "\n",
    "# training prediction\n",
    "count_correct = 0\n",
    "for i in range(len(data_small)):\n",
    "    pred_tag = shape_probs[data_small.iloc[i]['shape']]\n",
    "    pred_train.append(pred_tag)\n",
    "    if data_small.iloc[i]['tag'] == pred_tag:\n",
    "        count_correct += 1\n",
    "train_accuracy = 1.0*count_correct / len(data_small)\n",
    "print \"Train Accuracy: \" + str(train_accuracy)\n",
    "\n",
    "# validation prediction\n",
    "count_correct = 0\n",
    "for i in range(len(data_valid)):\n",
    "    pred_tag = shape_probs[data_valid.iloc[i]['shape']]\n",
    "    pred_train.append(pred_tag)\n",
    "    if data_valid.iloc[i]['tag'] == pred_tag:\n",
    "        count_correct += 1\n",
    "train_accuracy = 1.0*count_correct / len(data_valid)\n",
    "print \"Validation Accuracy: \" + str(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of data without a tag (Baseline accuracy if we only predict 'O': 0.846952875635\n",
      "Train Accuracy: 0.87527\n",
      "Validation Accuracy: 0.876297525951\n"
     ]
    }
   ],
   "source": [
    "pred_train = []\n",
    "pred_valid = []\n",
    "\n",
    "# make predictions based off of \"shape\"\n",
    "\n",
    "num_O = len(data[data['tag'] == 'O'])\n",
    "percent = 1.0*num_O/len(data)\n",
    "print \"Percent of data without a tag (Baseline accuracy if we only predict 'O': \" + str(percent)\n",
    "\n",
    "# training prediction\n",
    "count_correct = 0\n",
    "for i in range(len(data_small)):\n",
    "    pred_tag = pos_probs[data_small.iloc[i]['pos']]\n",
    "    pred_train.append(pred_tag)\n",
    "    if data_small.iloc[i]['tag'] == pred_tag:\n",
    "        count_correct += 1\n",
    "train_accuracy = 1.0*count_correct / len(data_small)\n",
    "print \"Train Accuracy: \" + str(train_accuracy)\n",
    "\n",
    "# validation prediction\n",
    "count_correct = 0\n",
    "for i in range(len(data_valid)):\n",
    "    pred_tag = pos_probs[data_valid.iloc[i]['pos']]\n",
    "    pred_train.append(pred_tag)\n",
    "    if data_valid.iloc[i]['tag'] == pred_tag:\n",
    "        count_correct += 1\n",
    "train_accuracy = 1.0*count_correct / len(data_valid)\n",
    "print \"Validation Accuracy: \" + str(train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are good prelim models, but we need to store probabilities differently to follow the Viterbi algorithm and incorporate multiple aspects of our dataset into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'I-art', u'B-gpe', u'B-art', u'I-per', u'I-tim', u'B-org', u'O', u'B-geo', u'B-tim', u'I-geo', u'B-per', u'I-eve', u'B-eve', u'I-gpe', u'I-org', u'I-nat', u'B-nat']\n",
      "\n",
      "{u'mixedcase': {}, u'lowercase': {}, u'camelcase': {}, u'ending-dot': {}, u'number': {}, u'capitalized': {}, u'abbreviation': {}, u'punct': {}, u'other': {}, u'uppercase': {}, u'contains-hyphen': {}}\n",
      "\n",
      "{u'PRP$': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.04878048780487805, 'B-org': 0.024390243902439025, 'O': 19.73170731707317, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.04878048780487805, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'VBG': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 44.5609756097561, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'VBD': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 89.92682926829268, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'VBN': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 74.8048780487805, 'B-geo': 0.024390243902439025, 'I-org': 0.04878048780487805, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u',': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.36585365853658536, 'B-org': 0.024390243902439025, 'O': 74.21951219512195, 'B-geo': 0.024390243902439025, 'I-org': 0.12195121951219512, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.04878048780487805, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'VBP': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 37.41463414634146, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'WDT': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.04878048780487805, 'B-org': 0.024390243902439025, 'O': 8.585365853658537, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'JJ': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 30.195121951219512, 'B-art': 0.0975609756097561, 'I-tim': 0.24390243902439024, 'B-org': 0.9512195121951219, 'O': 143.6341463414634, 'B-geo': 1.5365853658536586, 'I-org': 0.1951219512195122, 'I-geo': 0.07317073170731707, 'I-per': 0.024390243902439025, 'I-eve': 0.04878048780487805, 'B-eve': 0.024390243902439025, 'I-gpe': 0.36585365853658536, 'B-tim': 2.317073170731707, 'I-nat': 0.024390243902439025, 'B-per': 0.2682926829268293}, u'WP': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 5.682926829268292, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'VBZ': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 59.24390243902439, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'DT': {'I-art': 0.04878048780487805, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.04878048780487805, 'I-tim': 0.07317073170731707, 'B-org': 0.4878048780487805, 'O': 229.609756097561, 'B-geo': 0.43902439024390244, 'I-org': 0.07317073170731707, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.3902439024390244, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'RP': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 5.682926829268292, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'$': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 2.1219512195121952, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'NN': {'I-art': 0.04878048780487805, 'B-nat': 0.024390243902439025, 'B-gpe': 0.24390243902439024, 'B-art': 0.07317073170731707, 'I-tim': 1.8780487804878048, 'B-org': 0.5609756097560976, 'O': 335.4634146341463, 'B-geo': 0.2682926829268293, 'I-org': 0.4878048780487805, 'I-geo': 0.24390243902439024, 'I-per': 0.0975609756097561, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.04878048780487805, 'B-tim': 1.5121951219512195, 'I-nat': 0.024390243902439025, 'B-per': 0.24390243902439024}, u'POS': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.04878048780487805, 'B-org': 0.0975609756097561, 'O': 24.829268292682926, 'B-geo': 0.024390243902439025, 'I-org': 0.4878048780487805, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.07317073170731707, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'.': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 110.58536585365853, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'TO': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.2926829268292683, 'B-org': 0.024390243902439025, 'O': 52.75609756097561, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.04878048780487805, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'PRP': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 31.463414634146343, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'RB': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.17073170731707318, 'B-org': 0.024390243902439025, 'O': 47.80487804878049, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.6585365853658537, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u';': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 0.8048780487804879, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u':': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.17073170731707318, 'B-org': 0.04878048780487805, 'O': 1.5365853658536586, 'B-geo': 0.024390243902439025, 'I-org': 0.07317073170731707, 'I-geo': 0.04878048780487805, 'I-per': 0.04878048780487805, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'NNS': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 3.268292682926829, 'B-art': 0.024390243902439025, 'I-tim': 0.2682926829268293, 'B-org': 0.3170731707317073, 'O': 173.0, 'B-geo': 0.12195121951219512, 'I-org': 0.43902439024390244, 'I-geo': 0.04878048780487805, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.0975609756097561, 'B-tim': 0.6097560975609756, 'I-nat': 0.024390243902439025, 'B-per': 0.07317073170731707}, u'NNP': {'I-art': 0.9024390243902439, 'B-nat': 0.7317073170731707, 'B-gpe': 8.829268292682928, 'B-art': 1.6585365853658536, 'I-tim': 1.7804878048780488, 'B-org': 43.02439024390244, 'O': 12.341463414634147, 'B-geo': 78.1219512195122, 'I-org': 29.609756097560975, 'I-geo': 13.073170731707316, 'I-per': 44.80487804878049, 'I-eve': 0.975609756097561, 'B-eve': 1.2195121951219512, 'I-gpe': 0.6341463414634146, 'B-tim': 27.804878048780488, 'I-nat': 0.2926829268292683, 'B-per': 40.1219512195122}, u'``': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.04878048780487805, 'B-org': 0.024390243902439025, 'O': 8.902439024390244, 'B-geo': 0.024390243902439025, 'I-org': 0.07317073170731707, 'I-geo': 0.07317073170731707, 'I-per': 0.07317073170731707, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.04878048780487805, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'WRB': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 5.512195121951219, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'RRB': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 1.7804878048780488, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'CC': {'I-art': 0.04878048780487805, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.7560975609756098, 'B-org': 0.0975609756097561, 'O': 53.36585365853659, 'B-geo': 0.024390243902439025, 'I-org': 1.3414634146341464, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.04878048780487805, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'PDT': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 0.43902439024390244, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'RBS': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 0.6097560975609756, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'RBR': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 2.5121951219512195, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.04878048780487805, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'CD': {'I-art': 0.04878048780487805, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 6.2682926829268295, 'B-org': 0.024390243902439025, 'O': 39.609756097560975, 'B-geo': 0.07317073170731707, 'I-org': 0.0975609756097561, 'I-geo': 0.04878048780487805, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.07317073170731707, 'I-gpe': 0.024390243902439025, 'B-tim': 9.073170731707316, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'NNPS': {'I-art': 0.04878048780487805, 'B-nat': 0.04878048780487805, 'B-gpe': 0.024390243902439025, 'B-art': 0.07317073170731707, 'I-tim': 0.024390243902439025, 'B-org': 0.3170731707317073, 'O': 0.4146341463414634, 'B-geo': 0.04878048780487805, 'I-org': 1.6585365853658536, 'I-geo': 2.975609756097561, 'I-per': 0.04878048780487805, 'I-eve': 0.17073170731707318, 'B-eve': 0.07317073170731707, 'I-gpe': 0.17073170731707318, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.0975609756097561}, u'EX': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 1.4878048780487805, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'IN': {'I-art': 0.07317073170731707, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 1.2439024390243902, 'B-org': 0.04878048780487805, 'O': 279.0, 'B-geo': 0.04878048780487805, 'I-org': 1.4878048780487805, 'I-geo': 0.4634146341463415, 'I-per': 0.0975609756097561, 'I-eve': 0.04878048780487805, 'B-eve': 0.024390243902439025, 'I-gpe': 0.07317073170731707, 'B-tim': 2.024390243902439, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'WP$': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 0.21951219512195122, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'MD': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 16.073170731707318, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'LRB': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 1.7804878048780488, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'JJS': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.07317073170731707, 'B-org': 0.024390243902439025, 'O': 7.048780487804878, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'JJR': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.04878048780487805, 'B-org': 0.024390243902439025, 'O': 7.463414634146342, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.0975609756097561, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'VB': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.07317073170731707, 'O': 55.390243902439025, 'B-geo': 0.12195121951219512, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}, u'UH': {'I-art': 0.024390243902439025, 'B-nat': 0.024390243902439025, 'B-gpe': 0.024390243902439025, 'B-art': 0.024390243902439025, 'I-tim': 0.024390243902439025, 'B-org': 0.024390243902439025, 'O': 0.04878048780487805, 'B-geo': 0.024390243902439025, 'I-org': 0.024390243902439025, 'I-geo': 0.024390243902439025, 'I-per': 0.024390243902439025, 'I-eve': 0.024390243902439025, 'B-eve': 0.024390243902439025, 'I-gpe': 0.024390243902439025, 'B-tim': 0.024390243902439025, 'I-nat': 0.024390243902439025, 'B-per': 0.024390243902439025}}\n"
     ]
    }
   ],
   "source": [
    "# instead, for the purpose of extending the model, make shape_probs and \n",
    "# commit_probs hold dictionaries for the probabilities of each tag\n",
    "\n",
    "\n",
    "# build a dict linking shape to likelihood of each tag\n",
    "\n",
    "shape_probs = {}\n",
    "pos_probs = {}\n",
    "\n",
    "# if X shape, then what is the most likely tag?\n",
    "\n",
    "print(tag_list)\n",
    "print\n",
    "\n",
    "alpha = 1.0\n",
    "\n",
    "for shape in shape_list:\n",
    "    tag_prob_dict = {}\n",
    "    for tag in tag_list:\n",
    "        count = 0\n",
    "        for i in data_small[data_small['shape'] == shape]['tag']:\n",
    "            if i == tag:\n",
    "                count += 1\n",
    "        tag_prob_dict2.update({str(tag) : (1.0*count + alpha)/(len(data_small[data_small['shape'] == shape]) + alpha*len(shape_list))})\n",
    "    shape_probs[shape] = tag_prob_dict\n",
    "    \n",
    "for pos in pos_list:\n",
    "    tag_prob_dict = {}\n",
    "    for tag in tag_list:\n",
    "        count = 0\n",
    "        for i in data_small[data_small['pos'] == pos]['tag']:\n",
    "            if i == tag:\n",
    "                count += 1\n",
    "        tag_prob_dict.update({str(tag) : (1.0*count + alpha)/(len(data_small[data_small['shape'] == pos]) + 1.0*len(pos_list))})\n",
    "    pos_probs[pos] = tag_prob_dict\n",
    "\n",
    "print(shape_probs)\n",
    "print\n",
    "print(pos_probs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# follow the same procedure for each word. This may take a while to run\n",
    "\n",
    "\n",
    "# build a dict linking shape to likelihood of each tag\n",
    "\n",
    "word_list = list(set(x_train['word']))\n",
    "word_probs = {}\n",
    "alpha = 1.0\n",
    "\n",
    "# if X shape, then what is the most likely tag?\n",
    "\n",
    "print(tag_list)\n",
    "print\n",
    "\n",
    "for word in word_list:\n",
    "    tag_prob_dict = {}\n",
    "    for tag in tag_list:\n",
    "        count = 0\n",
    "        for i in data_small[data_small['word'] == word]['tag']:\n",
    "            if i == tag:\n",
    "                count += 1\n",
    "        tag_prob_dict[tag] = (1.0*count + alpha)/(len(data_small[data_small['shape'] == shape]) + alpha*len(word_list))\n",
    "    shape_probs[shape] = tag_prob_dict\n",
    "\n",
    "print(word_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now re-write the prediction algorithm to take the max probability for one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then we can incorporate multiple features in the algorithm by multiply probabilities and taking a max\n",
    "# or adding log probabilities. This is more complicated, but will evertually be the basis of the final model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data science work (maybe CV) to tune the model, figure out which features are most predictive\n",
    "# additionally, test out working with other features that we can extract (without breaking independence\n",
    "# assumptions of the HMM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
